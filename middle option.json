{
  "id": "9ae6082b-c7f4-433c-9971-7a8f65a3ea65",
  "revision": 0,
  "last_node_id": 72,
  "last_link_id": 94,
  "nodes": [
    {
      "id": 39,
      "type": "CLIPLoader",
      "pos": [
        195.5970509399467,
        419.9730316989669
      ],
      "size": [
        270,
        125
      ],
      "flags": {
        "collapsed": false,
        "pinned": true
      },
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            44,
            78
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.73",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "qwen_3_4b.safetensors",
            "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors",
            "directory": "text_encoders"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "clip_name": true,
            "type": true,
            "device": true
          },
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "qwen_3_4b.safetensors",
        "lumina2",
        "default"
      ]
    },
    {
      "id": 40,
      "type": "VAELoader",
      "pos": [
        195.5970509399467,
        569.9727563193524
      ],
      "size": [
        270,
        68.33333333333334
      ],
      "flags": {
        "collapsed": false
      },
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            39
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.73",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "ae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors",
            "directory": "vae"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "vae_name": true
          },
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "ae.safetensors"
      ]
    },
    {
      "id": 56,
      "type": "Note",
      "pos": [
        966.5602839744536,
        114.40864951696366
      ],
      "size": [
        210,
        88
      ],
      "flags": {
        "collapsed": false,
        "pinned": true
      },
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "LoRA trigger word",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Pixel art style"
      ],
      "color": "#432",
      "bgcolor": "#000"
    },
    {
      "id": 41,
      "type": "EmptySD3LatentImage",
      "pos": [
        194.38068362926754,
        715.4485335918812
      ],
      "size": [
        260,
        125
      ],
      "flags": {
        "collapsed": false,
        "pinned": true
      },
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            73
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "EmptySD3LatentImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "width": true,
            "height": true,
            "batch_size": true
          },
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1310.017603860965,
        273.8576676955248
      ],
      "size": [
        780,
        883.3333333333334
      ],
      "flags": {
        "collapsed": false,
        "pinned": true
      },
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 62
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "SaveImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "filename_prefix": true
          },
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "z-image"
      ]
    },
    {
      "id": 35,
      "type": "MarkdownNote",
      "pos": [
        -324.66667276016227,
        254.71836029077429
      ],
      "size": [
        210,
        34
      ],
      "flags": {
        "collapsed": true
      },
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model link",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "## Report workflow issue\n\nIf you found any issues when running this workflow, [report template issue here](https://github.com/Comfy-Org/workflow_templates/issues)\n\n\n## Model links\n\n**text_encoders**\n\n- [qwen_3_4b.safetensors](https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors)\n\n**loras**\n\n- [pixel_art_style_z_image_turbo.safetensors](https://huggingface.co/tarn59/pixel_art_style_lora_z_image_turbo/resolve/main/pixel_art_style_z_image_turbo.safetensors)\n\n**diffusion_models**\n\n- [z_image_turbo_bf16.safetensors](https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/diffusion_models/z_image_turbo_bf16.safetensors)\n\n**vae**\n\n- [ae.safetensors](https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors)\n\n\nModel Storage Location\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€â”€ ðŸ“‚ models/\nâ”‚   â”œâ”€â”€ ðŸ“‚ text_encoders/\nâ”‚   â”‚      â””â”€â”€ qwen_3_4b.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ loras/\nâ”‚   â”‚      â””â”€â”€ pixel_art_style_z_image_turbo.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚      â””â”€â”€ z_image_turbo_bf16.safetensors\nâ”‚   â””â”€â”€ ðŸ“‚ vae/\nâ”‚          â””â”€â”€ ae.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#000"
    },
    {
      "id": 44,
      "type": "KSampler",
      "pos": [
        971.9430596969835,
        375.83660984821836
      ],
      "size": [
        315,
        473.99739583333337
      ],
      "flags": {
        "collapsed": false,
        "pinned": true
      },
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 83
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 75
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 77
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 73
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            38
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "KSampler",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "seed": true,
            "steps": true,
            "cfg": true,
            "sampler_name": true,
            "scheduler": true,
            "denoise": true
          },
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        66069675613050,
        "fixed",
        8,
        1,
        "euler",
        "beta",
        1
      ]
    },
    {
      "id": 47,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        965.5975035377701,
        249.9728891454767
      ],
      "size": [
        310,
        68.33333333333334
      ],
      "flags": {
        "collapsed": false,
        "pinned": true
      },
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 94
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            83
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "shift": true
          },
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        3
      ]
    },
    {
      "id": 43,
      "type": "VAEDecode",
      "pos": [
        1305.3339866341855,
        154.7182681773523
      ],
      "size": [
        210,
        60
      ],
      "flags": {
        "collapsed": false,
        "pinned": true
      },
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 38
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 39
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            62
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "VAEDecode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": []
    },
    {
      "id": 61,
      "type": "CLIPTextEncode",
      "pos": [
        516.2389502818959,
        724.0830860779013
      ],
      "size": [
        400,
        200
      ],
      "flags": {
        "pinned": true
      },
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 78
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            77
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.6.0",
        "Node name for S&R": "CLIPTextEncode",
        "ue_properties": {
          "widget_ue_connectable": {
            "text": true
          },
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "anime, cartoon, illustration, painting, doll, plastic skin,\nover-smoothed face, exaggerated eyes, deformed anatomy,\nwide jaw, heavy makeup, unrealistic body proportions,\ncelebrity likeness, identity copying, face swap"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 45,
      "type": "CLIPTextEncode",
      "pos": [
        511.72819990162986,
        293.4501233806896
      ],
      "size": [
        410,
        370
      ],
      "flags": {
        "collapsed": false,
        "pinned": true
      },
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 44
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            75
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.73",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "text": true
          },
          "version": "7.5.2",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "Young woman in her early 20s, natural East Asian facial features with soft proportions, oval face and gentle jawline, medium-sized eyes with subtle gray-blue tone, natural eye spacing, small straight nose, soft pink lips with natural moisture, fair skin with visible texture, tiny pores on nose and cheeks, faint under-eye shadows, uneven natural redness, dark brown hair tied loosely with wet strands sticking to her face, wispy bangs slightly messy, slim petite body type, narrow shoulders, slender neck and collarbones, subtle asymmetry in facial structure, no beauty retouching, no skin smoothing.\nPose & body language (completely different energy):\nShe sits backwards on the chair, straddling it casually, elbows resting on the chairâ€™s backrest. Her upper body leans forward slightly, compressing posture in a way that feels intimate and unguarded. One leg is bent, the other extended loosely, toes resting on the floor. The pose feels natural, unposedâ€”like she stopped mid-movement.\nHands & micro-detail (this is where the lust lives):\nOne hand grips the top edge of the chair loosely, knuckles relaxed. The other hand is absent from the frame or resting low on the thigh, not shown clearlyâ€”suggestive through omission, not exposure.\nExpression & gaze:\nHer head is tilted slightly downward, eyes looking up toward the camera from under relaxed brows. The gaze is steady, slow, and unblinkingâ€”quiet dominance. Lips are softly parted as if exhaling, no smile, no performance.\nClothing (explicit, different, realistic):\nShe wears an oversized white cotton button-down shirt, clearly a menâ€™s fitâ€”long sleeves pushed up messily to the forearms. The shirt is fully unbuttoned and covering only side shoulders, exposing the chest and collarbone area, fabric folding naturally with gravity. The hem of the shirt falls unevenly, revealing bare thighs beneath.The Shirt is made of thin fiber and completely wet and stick to body due to sweat, the breasts are completely visible, breast are slightly uplifted naturally and have uneven redness the are also sweaty, nipples are baby pink with visible texture.\nUnderneath, she wears minimal black fitted shorts barely visible under the shirt, tight at the hips, matte fabric.\nLighting (indoor sensuality, not neon):\nSoft window light from one side acts as the key light, cool-toned, diffused by thin curtains. A warm practical light from behind (lamp or hallway glow) creates depth and separation. Shadows fall naturally across her jawline, neck, and fabric folds.\nCamera & angle (new framing logic):\nShot on an 85mm portrait lens aesthetic for compression and intimacy. Camera placed at seated eye level, close enough to feel personal but not invasive. Framing from mid-thigh to head, shallow depth of field isolating her from the room.\nMood & realism:\nColor grading is soft and mutedâ€”warm skin tones against cool shadows. Skin texture remains fully realistic: pores, faint redness, natural imperfections visible. No beauty retouching, no glam styling. The mood is intimate, controlled, and quietly provocativeâ€”like being noticed when you werenâ€™t meant to be watched."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 67,
      "type": "UnetLoaderGGUF",
      "pos": [
        198.62526131164702,
        312.4151171808645
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            93
          ]
        }
      ],
      "properties": {
        "cnr_id": "ComfyUI-GGUF",
        "ver": "795e45156ece99afbc3efef911e63fcb46e6a20d",
        "Node name for S&R": "UnetLoaderGGUF",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {},
          "version": "7.5.2"
        }
      },
      "widgets_values": [
        "z-image-turbo-Q8_0.gguf"
      ]
    },
    {
      "id": 72,
      "type": "CacheDiT_Model_Optimizer",
      "pos": [
        511.1483765868533,
        34.78047819399623
      ],
      "size": [
        270,
        154
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 93
        }
      ],
      "outputs": [
        {
          "name": "optimized_model",
          "type": "MODEL",
          "links": [
            94
          ]
        }
      ],
      "properties": {
        "aux_id": "Jasonzzt/ComfyUI-CacheDiT",
        "ver": "206f2c4150d09615beb8a32202e1d3214008dfbd",
        "ue_properties": {
          "widget_ue_connectable": {},
          "input_ue_unconnectable": {}
        },
        "Node name for S&R": "CacheDiT_Model_Optimizer"
      },
      "widgets_values": [
        true,
        "Z-Image-Turbo",
        3,
        2,
        true
      ]
    }
  ],
  "links": [
    [
      38,
      44,
      0,
      43,
      0,
      "LATENT"
    ],
    [
      39,
      40,
      0,
      43,
      1,
      "VAE"
    ],
    [
      44,
      39,
      0,
      45,
      0,
      "CLIP"
    ],
    [
      62,
      43,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      73,
      41,
      0,
      44,
      3,
      "LATENT"
    ],
    [
      75,
      45,
      0,
      44,
      1,
      "CONDITIONING"
    ],
    [
      77,
      61,
      0,
      44,
      2,
      "CONDITIONING"
    ],
    [
      78,
      39,
      0,
      61,
      0,
      "CLIP"
    ],
    [
      83,
      47,
      0,
      44,
      0,
      "MODEL"
    ],
    [
      93,
      67,
      0,
      72,
      0,
      "MODEL"
    ],
    [
      94,
      72,
      0,
      47,
      0,
      "MODEL"
    ]
  ],
  "groups": [
    {
      "id": 2,
      "title": "Step2 - Image size",
      "bounding": [
        185.33333399376386,
        654.7182663398995,
        290,
        200
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step3 - Prompt",
      "bounding": [
        495.33333399376386,
        224.71826633989951,
        450,
        717.3854554546931
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Step1 - Load models",
      "bounding": [
        185.33333399376386,
        224.71826633989951,
        290,
        413.6
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 5,
      "title": "Ctrl-B to enable LoRA input",
      "bounding": [
        495.33333399376386,
        54.71826633989954,
        440,
        160
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.6728218560527595,
      "offset": [
        87.82146420321556,
        292.20057633159973
      ]
    },
    "frontendVersion": "1.37.11",
    "workflowRendererVersion": "LG",
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true,
    "ue_links": [],
    "links_added_by_ue": []
  },
  "version": 0.4
}